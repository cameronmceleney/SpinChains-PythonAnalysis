#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# Standard libraries
import logging as lg
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns

# Additional libraries
import csv as csv
from os import path

# My packages / Any header files
import system_preparation as sp
import plots_for_rk_methods as plt_rk

"""
    Description of what data_analysis does
"""
PROGRAM_NAME = "data_analysis.py"
"""
    Core Details
    
    Author      : cameronmceleney
    Created on  : 12/03/2022 19:02
    Filename    : data_analysis
    IDE         : PyCharm
"""


class ImportData:
    """
    Import data needed for plotting.

    Use class to import data, as multiple imports will use the same file directories, so this makes
    it easier to read on the overhead. Also means that methods can be called multiple times to allow
    multiple different plots to be generated by amending the arguments.
    """

    def __init__(self, filename_timestamp, filename_rk_method="rk2", filename_component="mx",
                 file_identifier="LLGTest"):
        self.full_file_name = f"{filename_rk_method}_{filename_component}_{file_identifier}{filename_timestamp}"

        self.input_dir_path = sp.directory_tree_testing()[0]
        self.output_dir_path = sp.directory_tree_testing()[1]

        self.input_data_path = f"{self.input_dir_path}{self.full_file_name}.csv"
        self.output_data_path = f"{self.output_dir_path}{file_identifier}{filename_timestamp}"


class ImportSingleFile(ImportData):

    def __init__(self, filename_timestamp, filename_rk_method, filename_component, file_identifier):
        super().__init__(filename_timestamp, filename_rk_method, filename_component, file_identifier)



    def import_from_single_file(self):
        """
        Outputs the data needed to plot single-image panes.

        Contained in single method to unify processing option. Separated from import_data_headers() (unlike in previous
        files) for when multiple datafiles, with the same header, are imported.
        """
        lg.info(f"Importing data points...")

        all_data_without_header = None
        # Loads all input data
        try:
            is_file_present_in_dir = path.exists(self.input_data_path)
            if not is_file_present_in_dir:
                raise FileNotFoundError
        except FileNotFoundError:
            print(f"File {self.full_file_name} was not found")
            exit(1)
        else:
            all_data_without_header = np.loadtxt(self.input_data_path, delimiter=",", skiprows=9)

        lg.info(f"Data points imported!")

        return all_data_without_header

    def import_data_headers(self):
        """
        Import the header lines of each csv file to obtain the C++ simulation parameters.

        Each simulation in C++ returns all the key parameters, required to replicate the simulation, as headers in csv
        files. This function imports that data, and creates dictionaries to store it.

        The Python dictionary keys are the same variable names as their C++ counterparts (for consistency). Casting is
        required as data comes from csvreader as strings.

        :return: Returns a tuple. [0] is the dictionary containing all the key simulation parameters. [1] is an array
        containing strings; the names of each spin site.
        """
        lg.info(f"Importing file headers...")

        with open(self.input_data_path) as file_header_data:
            csv_reader = csv.reader(file_header_data)
            next(csv_reader)  # 1st line. title_line
            next(csv_reader)  # 2nd line. Blank.
            next(csv_reader)  # 3rd line. Column title for each key simulation parameter. data_names
            data_values = next(csv_reader)  # 4th line. Values associated with column titles from 3rd line.
            next(csv_reader)  # 5th line. Blank.
            next(csv_reader)  # 6th line. Simulation notes. sim_notes
            next(csv_reader)  # 7th line. Describes how to understand column titles from 3rd line. data_names_explained
            next(csv_reader)  # 8th line. Blank.
            list_of_simulated_sites = next(csv_reader)  # 9th line. Number for each spin site that was simulated

        # Assignment to dict is done individually to improve readability.
        key_params = dict()
        key_params['biasField'] = float(data_values[0])
        key_params['biasFieldDriving'] = float(data_values[1])
        key_params['biasFieldDrivingScale'] = float(data_values[2])
        key_params['drivingFreq'] = float(data_values[3])
        key_params['drivingRegionLHS'] = int(data_values[4])
        key_params['drivingRegionRHS'] = int(data_values[5])
        key_params['drivingRegionWidth'] = int(data_values[6])
        key_params['maxSimTime'] = float(data_values[7])
        key_params['exchangeMaxVal'] = float(data_values[8])
        key_params['stopIterVal'] = float(data_values[9])
        key_params['exchangeMinVal'] = float(data_values[10])
        key_params['numberOfDataPoints'] = int(data_values[11])
        key_params['numSpins'] = int(data_values[12])
        key_params['stepsize'] = float(data_values[13])

        lg.info(f"File headers imported!")

        if "Time" in list_of_simulated_sites:
            list_of_simulated_sites.remove("Time")

        return key_params, list_of_simulated_sites


class ImportEigenmodes(ImportData):

    def __init__(self, filename_timestamp, filename_rk_method, filename_component, file_identifier):
        super().__init__(filename_timestamp, filename_rk_method, filename_component, file_identifier)

        # Arrays are inherently mutable, so there is no need to use @property decorator
        self.input_filenames_descriptions = ["mx_data", "my_data", "eigenvalues_data"]
        self._arrays_to_output = []  # Each array is initialised as none to remove garbage.
        self._does_data_exist_in_dir = []  # Tests if each filtered array is in the target directory.
        self.output_filenames = [f"mx_formatted_{self.full_file_name}.csv",
                                 f"my_formatted_{self.full_file_name}.csv",
                                 f"eigenvalues_formatted_{self.full_file_name}.csv"]

    def import_eigenmodes(self):
        # Containers to store key information about the returned arrays. Iterating through containers was felt to be
        # easier to read than having many lines of variable declarations and initialisations.

        print(f"\nChecking chosen directories for files...")

        for i, (output_file_description, output_file) in enumerate(
                zip(self.input_filenames_descriptions, self.output_filenames)):
            # Tests if the required files already exist in the target (input data) directory.
            file_to_search_for = self.input_dir_path + output_file

            if path.exists(file_to_search_for):
                self._arrays_to_output[i] = np.loadtxt(file_to_search_for, delimiter=',')
                self._does_data_exist_in_dir[i] = True
                print(f"{output_file_description}: found")

            else:
                self._does_data_exist_in_dir[i] = False
                print(f"{output_file_description}: not found")

        for i, does_exist in enumerate(self._does_data_exist_in_dir):
            # Tests existence of each filtered array until either False is returned, or all are present (all True).

            try:
                does_exist is True
            except ValueError:
                try:
                    does_exist is False
                except ValueError:
                    lg.info(f"Boolean variable (does_exist) was dtype None.")
                    exit(1)
                else:
                    self._generate_file_that_is_missing(i)
            else:
                print(f"{self.input_filenames_descriptions[i]} successfully found")

        else:
            print("All files successfully found!\n")

        return self._arrays_to_output[0], self._arrays_to_output[1], self._arrays_to_output[2]

    @staticmethod
    def _generate_file_that_is_missing(index):

        # Instance of missing file has been found, and will need to generate all filtered files that are needed.
        # Before doing so, allow user to opt-out.

        while True:
            generate_file_query = input('Run import code to generate missing files? y/n: ').upper()
            try:
                generate_file_query in "YN"
            except ValueError:
                continue
            else:
                if generate_file_query == 'Y':
                    if index in [0, 1]:
                        print('self._generate_missing_eigenvectors()')
                        return
                    elif index == 2:
                        print('self._generate_missing_eigenvalues()')
                        return
                    else:
                        lg.error(f"Index of value {index} was called")
                        return
                elif generate_file_query == 'N':
                    print("\nWill not generate files. Exiting...\n")
                    lg.info("User chose to not generate missing files. Code exited.")
                    exit(0)

    def _generate_missing_eigenvalues(self):

        lg.info(f"Missing Eigenvalues file found. Attempting to generate new file in correct format...")

        # 'Raw' refers to the data produces from the C++ code.
        eigenvalues_raw = np.loadtxt(f"{self.input_dir_path}eigenvalues_{self.full_file_name}.csv",
                                     delimiter=",")

        # Filtered refers to the data imported into, and amended by, this Python code.
        eigenvalues_filtered = np.flipud(eigenvalues_raw[::2])

        # Use np.savetxt to save the data (2nd parameter) directly to the files (first parameter).
        np.savetxt(f"{self.input_dir_path}{self.output_filenames[2]}", eigenvalues_filtered,
                   delimiter=',')

        lg.info(f"Successfully generated missing (eigenvalues) file, which is saved in {self.input_dir_path}")

    def _generate_missing_eigenvectors(self):

        lg.info(f"Missing (mx) and/or (my) file(s) found. Attempting to generate new files in correct format...")

        # 'Raw' refers to the data produces from the C++ code.
        eigenvectors_raw = np.loadtxt(f"{self.input_dir_path}eigenvectors_{self.full_file_name}.csv",
                                      delimiter=",")

        # Filtered refers to the data imported into, and amended by, this Python code.
        eigenvectors_filtered = np.fliplr(eigenvectors_raw[::2, :])

        mx_data = eigenvectors_filtered[:, 0::2]
        my_data = eigenvectors_filtered[:, 1::2]

        # Use np.savetxt to save the data (2nd parameter) directly to the files (first parameter).
        np.savetxt(f"{self.input_dir_path}{self.output_filenames[0]}", mx_data, delimiter=',')
        np.savetxt(f"{self.input_dir_path}{self.output_filenames[1]}", my_data, delimiter=',')

        lg.info(f"Successfully generated missing (mx) and (my) files, which are saved in {self.input_dir_path}")


class PlotImportedData:
    """
    Test class to handle the full importing of data.

    Previously, functions could only handle a single input. This meant the program had to be compiled each time the
    target dataset was altered; a huge pain.
    """

    def __init__(self, file_descriptor, file_prefix="rk2", file_component="mx", file_identifier="LLGTest"):
        self.fd = file_descriptor
        self.fp = file_prefix
        self.fc = file_component
        self.fi = file_identifier

        rc_params_update()

        self.full_filename = f"{file_prefix}_{file_component}_{file_identifier}{file_descriptor}"
        self.full_output_path = f"{sp.directory_tree_testing()[1]}{file_identifier}{file_descriptor}"
        self.data_absolute_path = f"{sp.directory_tree_testing()[0]}{self.full_filename}.csv"


class PlotEigenmodes(PlotImportedData):

    def __init__(self, file_descriptor, file_prefix, file_component, file_identifier):
        super().__init__(file_descriptor, file_prefix, file_component, file_identifier)

        eigenmodes_data = ImportEigenmodes(self.fd, self.fp, self.fc, self.fi)
        eigenmodes_data.import_eigenmodes()
        [self.mx_data, self.my_data, self.eigenvalues_data] = eigenmodes_data

    def plot_eigenmodes(self):
        lg.info(f"Invoking functions to plot data...")
        plt_rk.eigenmodes(self.mx_data, self.my_data, self.eigenvalues_data, self.full_filename)


class SelectMethodToPlot(PlotImportedData):

    def __init__(self, file_descriptor, file_prefix, file_component, file_identifier):
        super().__init__(file_descriptor, file_prefix, file_component, file_identifier)

        imported_data = ImportSingleFile(self.fd, self.fp, self.fc, self.fi)
        self.all_imported_data = imported_data.import_from_single_file()

        [self.header_data_params, self.header_data_sites] = imported_data.import_data_headers()

        self.m_time_data = self.all_imported_data[:, 0] / 1e-9  # Convert to from [seconds] to [ns]
        self.m_spin_data = self.all_imported_data[:, 1:]

        self.accepted_keywords = ["3P", "FS", "EXIT", "PF"]

    def call_methods(self):

        lg.info(f"Invoking functions to plot data...")

        print('\n---------------------------------------------------------------------------------------')
        print('''
        The plotting functions available are:

            *   Three Panes  [3P] (Plot all spin sites varying in time, and compare a selection)
            *   FFT & Signal [FS] (Examine signals from site(s), and the corresponding FFT)
            *   Paper Figure [PF] (Plot final state of system at all sites)

        The terms within the square brackets are the keys for each function. 
        If you wish to exit the program then type EXIT. Keys are NOT case-sensitive.
                  ''')
        print('---------------------------------------------------------------------------------------\n')

        initials_of_method_to_call = input("Which function to use: ").upper()

        while True:
            if initials_of_method_to_call in self.accepted_keywords:
                self._data_plotting_selections(initials_of_method_to_call)
                break
            else:
                while initials_of_method_to_call not in self.accepted_keywords:
                    initials_of_method_to_call = input("Invalid option. Select function should to use: ").upper()

        print("Code complete!")
        lg.info(f"Code complete! Exiting.")

    def _data_plotting_selections(self, method_to_call):

        if method_to_call == "3P":
            self._invoke_three_panes()

        elif method_to_call == "FS":
            self._invoke_fft_functions()

        elif method_to_call == "PF":
            self._invoke_paper_figures()

        elif method_to_call == "EXIT":
            self._exit_conditions()

    def _invoke_three_panes(self):
        # Use this if you wish to see what ranplotter.py would output
        lg.info(f"Plotting function selected: three panes.")
        print("Note: To select sites to compare, edit code directly.")
        print("Generating plot...")
        plt_rk.three_panes(self.all_imported_data, self.header_data_params, self.header_data_sites,
                           self.full_output_path,
                           [3, 4, 5])
        lg.info(f"Plotting 3P complete!")

    def _invoke_fft_functions(self):
        # Use this to see fourier transforms of data

        lg.info(f"Plotting function selected: Fourier Signal.")

        has_more_to_plot = True
        while has_more_to_plot:
            # User will plot one spin site at a time, as plotting can take a long time.
            target_spin = int(input("Plot which spin (-ve to exit): "))
            print("Generating plot...")

            if target_spin >= 1:
                plt_rk.fft_and_signal_four(self.m_time_data, self.m_spin_data[:, target_spin], target_spin,
                                           self.header_data_params,
                                           self.full_output_path)
                lg.info(f"Finished plotting spin site #{target_spin} in FS. Continuing...")
                # cont_plotting_FFT = False  # Remove this after testing.
            else:
                has_more_to_plot = False

        lg.info(f"Completed plotting FS!")

    def _invoke_paper_figures(self, has_override=False, override_name="PNG"):
        # Plots final state of system, similar to the Figs. in macedo2021breaking.
        lg.info(f"Plotting function selected: paper figure.")

        print("Generating plot...")
        paper_fig = plt_rk.PaperFigures(self.m_time_data, self.m_spin_data,
                                        self.header_data_params, self.header_data_sites,
                                        self.full_output_path)

        if has_override:
            pf_selection = override_name
        else:
            pf_selection = str(input("Which figure should be created: "))

        if pf_selection == "PNG":
            paper_fig.create_png()
        elif pf_selection == "SV":
            paper_fig.plot_site_variation(401)
        elif pf_selection == "GIF":
            paper_fig.create_gif(number_of_frames=0.01)

        lg.info(f"Plotting PF complete!")

    @staticmethod
    def _exit_conditions():
        print("Exiting program...")
        lg.info(f"Exiting program from (select_plotter == EXIT)!")
        exit(0)


def data_analysis(file_descriptor, file_prefix="rk2_mx_", file_identifier="LLGTest", breaking_paper=False):
    """
    Import a dataset in csv format, plotting the signal and the corresponding FFTs, for a user-defined number of sites.

    -----
    Notes
    -----

    Ensure that the first column of the dataset are the timestamps that each measurement was taken at. If this is not
    the case, then replace the variable 'mx_time' with an array of values:

    * mx_time = np.linspace(start_time, end_time, number_of_iterations, endpoint=True)

    :param str file_prefix: This is the 'file_identity' variable in the C++ code.
    :param str file_identifier: This is the 'filename' variable in the C++ code.
    :param str file_descriptor: The file_ext variable in the C++ code. Set as a function argument to reduce user inputs
    :param bool breaking_paper: Temporary argument to allow for the user to plot eigenmodes from ranplotter.py (True),
    or signals (cpp_rk2_plot.py) (False).

    :return: Nothing.
    """
    rc_params_update()

    full_file_name = f"{file_prefix}{file_identifier}{file_descriptor}"
    full_output_path = f"{sp.directory_tree_testing()[1]}{file_identifier}{file_descriptor}"
    data_absolute_path = f"{sp.directory_tree_testing()[0]}{full_file_name}.csv"

    # Tracking how long the data import took is important for monitoring large files.
    lg.info(f"Invoking functions to import data..")

    if breaking_paper:
        # Used to plot figures from macedo2021breaking. Often used, so has a fast way to call.
        mx_data, my_data, eigen_vals_data = import_data(full_file_name, sp.directory_tree_testing()[0],
                                                        only_essentials=False)
        lg.info(f"All functions that import data are finished!")
        lg.info(f"Invoking functions to plot data...")
        plt_rk.eigenmodes(mx_data, my_data, eigen_vals_data, full_file_name)

    else:
        all_imported_data, [header_data_params, header_data_sites] = import_data(full_file_name, data_absolute_path,
                                                                                 only_essentials=True)

        m_time_data = all_imported_data[:, 0] / 1e-9  # Convert to from [seconds] to [ns]
        m_spin_data = all_imported_data[:, 1:]

        lg.info(f"All functions that import data are finished!")

        lg.info(f"Invoking functions to plot data...")

        print('\n---------------------------------------------------------------------------------------')
        print('''
    The plotting functions available are:
    
        *   Three Panes  [3P] (Plot all spin sites varying in time, and compare a selection)
        *   FFT & Signal [FS] (Examine signals from site(s), and the corresponding FFT)
        *   Paper Figure [PF] (Plot final state of system at all sites)
        
    The terms within the square brackets are the keys for each function. 
    If you wish to exit the program then type EXIT. Keys are NOT case-sensitive.
              ''')
        print('---------------------------------------------------------------------------------------\n')
        select_plotter = input("Which function to use: ").upper()
        while True:

            if select_plotter == '3P':
                # Use this if you wish to see what ranplotter.py would output
                lg.info(f"Plotting function selected: three panes.")
                print("Note: To select sites to compare, edit code directly.")
                print("Generating plot...")
                plt_rk.three_panes(all_imported_data, header_data_params, header_data_sites, full_output_path,
                                   [3, 4, 5])
                lg.info(f"Plotting 3P complete!")
                break

            elif select_plotter == 'FS':
                # Use this to see fourier transforms of data

                lg.info(f"Plotting function selected: Fourier Signal.")

                has_more_to_plot = True
                while has_more_to_plot:
                    # User will plot one spin site at a time, as plotting can take a long time.
                    target_spin = int(input("Plot which spin (-ve to exit): "))
                    print("Generating plot...")

                    if target_spin >= 1:
                        plt_rk.fft_and_signal_four(m_time_data, m_spin_data[:, target_spin], target_spin,
                                                   header_data_params,
                                                   full_output_path)
                        lg.info(f"Finished plotting spin site #{target_spin} in FS. Continuing...")
                        # cont_plotting_FFT = False  # Remove this after testing.
                    else:
                        has_more_to_plot = False

                lg.info(f"Completed plotting FS!")
                break  # Break out of elif statement

            elif select_plotter == "PF":
                # Plots final state of system, similar to the Figs. in macedo2021breaking.
                lg.info(f"Plotting function selected: paper figure.")

                print("Generating plot...")
                paper_fig = plt_rk.PaperFigures(m_time_data, m_spin_data,
                                                header_data_params, header_data_sites,
                                                full_output_path)
                # paper_fig.create_png()
                paper_fig.plot_site_variation(1600)
                # paper_fig.create_gif(number_of_frames=0.001)

                lg.info(f"Plotting PF complete!")
                break

            elif select_plotter == 'EXIT':
                print("Exiting program...")
                lg.info(f"Exiting program from (select_plotter == EXIT)!")

                exit(0)

            else:
                while select_plotter not in ["3P", "FS", "EXIT", "PF"]:
                    select_plotter = input("Invalid option. Select function should to use: ").upper()

        print("Code complete!")
        lg.info(f"Code complete! Exiting.")

        exit(0)


def rc_params_update():
    """Container for program's custom rc params, as well as Seaborn (library) selections."""
    plt.style.use('fivethirtyeight')
    sns.set(context='notebook', font='Kohinoor Devanagari', palette='muted', color_codes=True)
    ##############################################################################
    # Sets global conditions including font sizes, ticks and sheet style
    # Sets various font size. fsize: general text. lsize: legend. tsize: title. ticksize: numbers next to ticks
    fsize = 18
    lsize = 12
    tsize = 24
    ticksize = 14

    # sets the tick direction. Options: 'in', 'out', 'inout'
    t_dir = 'in'
    # sets the tick size(s) and tick width(w) for the major and minor axes of all plots
    t_maj_s = 10
    t_min_s = 5
    t_maj_w = 1.2
    t_min_w = 1

    # updates rcParams of the selected style with my preferred options for these plots. Feel free to change
    plt.rcParams.update({'axes.titlesize': tsize, 'axes.labelsize': fsize, 'font.size': fsize, 'legend.fontsize': lsize,
                         'xtick.labelsize': ticksize, 'ytick.labelsize': ticksize,
                         'axes.edgecolor': 'black', 'axes.linewidth': 1.2,
                         "xtick.bottom": True, "ytick.left": True,
                         'xtick.color': 'black', 'ytick.color': 'black', 'ytick.labelcolor': 'black',
                         'text.color': 'black',
                         'xtick.major.size': t_maj_s, 'xtick.major.width': t_maj_w,
                         'xtick.minor.size': t_min_s, 'xtick.minor.width': t_min_w,
                         'ytick.major.size': t_maj_s, 'ytick.major.width': t_maj_w,
                         'ytick.minor.size': t_min_s, 'ytick.minor.width': t_min_w,
                         'xtick.direction': t_dir, 'ytick.direction': t_dir,
                         'axes.spines.top': False, 'axes.spines.bottom': True, 'axes.spines.left': True,
                         'axes.spines.right': False,
                         'figure.titlesize': 24,
                         'figure.dpi': 300})


def import_data(file_name, input_filepath, only_essentials):
    """
    Imports, separates, formats, and returns the simulation data from the eigenvalue and eigenvector output csv files.

    The data needed can be obtained from the C++ code:

    * For only_essentials=True, use the outputs from 'SpinChainEigenSolver'.
    * For only_essentials=False, use the outputs from 'Numerical_Methods'.

    :param str file_name: Name of file to be imported. Note! This should not include a prefix like 'eigenvalues'
    :param str input_filepath: The absolute filepath to the dir containing input files.
    :param bool only_essentials: Streamlined option that is used for plotting panes.

    :return: Three arrays which can be used to generate all plots in plots_for_rk_methods.py.
    """

    if only_essentials:
        # Outputs the data needed to plot single-image panes
        lg.info(f"Importing data points...")

        # Loads all input data
        all_data_without_header = np.loadtxt(open(input_filepath, "rb"), delimiter=",", skiprows=9)
        header_data = import_data_headers(input_filepath)

        lg.info(f"Data points imported!")

        return all_data_without_header, header_data

    else:

        # Containers to store key information about the returned arrays. Iterating through containers was felt to be
        # easier to read than having many lines of variable declarations and initialisations.
        output_data_array_names = ["mx_data", "my_data", "eigenvalues_data"]  # Names of output data arrays found below.
        output_data_arrays = [None, None, None]  # Each array is initialised as none to ensure garbage isn't contained.
        does_data_exist = [False, False, False]  # Tests if each filtered array is in the target directory.
        filtered_filenames = [f"mx_formatted_{file_name}.csv", f"my_formatted_{file_name}.csv",
                              f"eigenvalues_formatted_{file_name}.csv"]  # filtered means being in the needed format

        print(f"\nChecking chosen directories for files...")

        for i, (array_name, file_name) in enumerate(zip(output_data_array_names, filtered_filenames)):

            if path.exists(input_filepath + file_name):
                # Check if each filtered data file (mx, my, eigenvalue) is in the target directory.
                output_data_arrays[i] = np.loadtxt(input_filepath + file_name, delimiter=',')
                does_data_exist[i] = True
                print(f"{array_name}: found")

            else:
                print(f"{array_name}: not found")

        for _, does_exist in enumerate(does_data_exist):
            # Tests existence of each filtered array until either False is returned, or all are present (all True).

            if not does_exist:
                # Generate all filtered files that are needed. Before doing so, allow user to opt-out.
                generate_files_response = input('Run import code to generate missing files? Y/N: ').upper()

                while True:
                    # Loops for as long as user input is accepted. Otherwise, forced them to comply.
                    if generate_files_response == 'Y':

                        # 'Raw' refers to the data produces from the C++ code.
                        eigenvalues_raw = np.loadtxt(f"{input_filepath}eigenvalues_{file_name}.csv", delimiter=",")
                        eigenvectors_raw = np.loadtxt(f"{input_filepath}eigenvectors_{file_name}.csv", delimiter=",")

                        # Filtered refers to the data imported into, and amended by, this Python code.
                        eigenvalues_filtered = np.flipud(eigenvalues_raw[::2])
                        eigenvectors_filtered = np.fliplr(eigenvectors_raw[::2, :])

                        mx_data = eigenvectors_filtered[:, 0::2]
                        my_data = eigenvectors_filtered[:, 1::2]

                        # Use np.savetxt to save the data (2nd parameter) directly to the files (first parameter).
                        np.savetxt(f"{input_filepath}{filtered_filenames[0]}", mx_data, delimiter=',')
                        np.savetxt(f"{input_filepath}{filtered_filenames[1]}", my_data, delimiter=',')
                        np.savetxt(f"{input_filepath}{filtered_filenames[2]}", eigenvalues_filtered, delimiter=',')

                        print(f"\nFiles successfully generated and save in {input_filepath}!\n")
                        break  # Exits while True: loop.

                    elif generate_files_response == 'N':
                        print("\nWill not generate files. Exiting...\n")
                        exit(0)

                    else:
                        while generate_files_response not in 'YN':
                            generate_files_response = input("Invalid selection, try again. Run import code to "
                                                            "generate missing files? Y/N: ").upper()

        else:
            #
            print("All files successfully found!\n")

        return output_data_arrays[0], output_data_arrays[1], output_data_arrays[2]


def import_data_headers(filename):
    """
    Import the header lines of each csv file to obtain the C++ simulation parameters.

    Each simulation in C++ returns all the key parameters, required to replicate the simulation, as headers in csv
    files. This function imports that data, and creates dictionaries to store it.

    The Python dictionary keys are the same variable names as their C++ counterparts (for consistency). Casting is
    required as data comes from csvreader as strings.

    :param str filename: The filename of the data to be imported. Obtained from data_analysis.data_analysis()

    :return: Returns a tuple. [0] is the dictionary containing all the key simulation parameters. [1] is an array
    containing strings; the names of each spin site.
    """
    lg.info(f"Importing file headers...")

    with open(filename) as file_header_data:
        csv_reader = csv.reader(file_header_data)
        next(csv_reader)  # 1st line. title_line
        next(csv_reader)  # 2nd line. Blank.
        next(csv_reader)  # 3rd line. Column title for each key simulation parameter. data_names
        data_values = next(csv_reader)  # 4th line. Values associated with column titles from 3rd line.
        next(csv_reader)  # 5th line. Blank.
        next(csv_reader)  # 6th line. Simulation notes. sim_notes
        next(csv_reader)  # 7th line. Describes how to understand column titles from 3rd line. data_names_explained
        next(csv_reader)  # 8th line. Blank.
        simulated_spin_sites = next(csv_reader)  # 9th line. Number for each spin site that was simulated

    # Assignment to dict is done individually to improve readability.
    key_params = dict()
    key_params['biasField'] = float(data_values[0])
    key_params['biasFieldDriving'] = float(data_values[1])
    key_params['biasFieldDrivingScale'] = float(data_values[2])
    key_params['drivingFreq'] = float(data_values[3])
    key_params['drivingRegionLHS'] = int(data_values[4])
    key_params['drivingRegionRHS'] = int(data_values[5])
    key_params['drivingRegionWidth'] = int(data_values[6])
    key_params['maxSimTime'] = float(data_values[7])
    key_params['exchangeMaxVal'] = float(data_values[8])
    key_params['stopIterVal'] = float(data_values[9])
    key_params['exchangeMinVal'] = float(data_values[10])
    key_params['numberOfDataPoints'] = int(data_values[11])
    key_params['numSpins'] = int(data_values[12])
    key_params['stepsize'] = float(data_values[13])

    lg.info(f"File headers imported!")

    if "Time" in simulated_spin_sites:
        simulated_spin_sites.remove("Time")

    return key_params, simulated_spin_sites
